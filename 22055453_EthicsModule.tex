\documentclass[14pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[style=authoryear,backend=biber]{biblatex}
\usepackage{csquotes}
\usepackage[margin=2.5cm]{geometry}
\usepackage{titlesec}
\usepackage{appendix}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{fancyhdr}
\usepackage{xurl}
\usepackage{multicol}

\addbibresource{references.bib}

\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}

  \title{Report and Recommendations\\ `Alice' \\ Ethical Considerations for AI in Education}
\author{Enzo Joly, 22055453}
\date{}


\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{TechSoft Internal Report: Ethical Considerations for Development of `Alice'}
\fancyhead[R]{Page \thepage}
\fancyfoot[C]{\thepage}

\begin{document}

\maketitle

\hrule

\vspace{3em}

Module Title: UFCFB5-15-3 | Ethical and Professional Issues in Computing and Digital Media

Word Count: 2,048

\vspace{3em}
\hrule




\thispagestyle{empty}

\newpage

\tableofcontents
\pagenumbering{roman}

\newpage

\pagenumbering{arabic}

\begin{multicols}{2}
\section{Introduction}
This report comprises ethical considerations and analysis concerning technology, data privacy, disinformation, and accessibility.

The resulting recommendations for deployment aim to inform, such that TechSoft be fully cognisant of challenges faced by an AI chatbot in education.
South Star Academy's proposed student support services chatbot `Alice' will require thoughtful diligence before it can be deemed production-ready.

%Public Interest
%Data Governance Policy
%Escalation Policy

%What ethical or social issues are important for this project?

%What professional, legal or design standards might the organisation need to read and implement?

%What can YOU suggest as KEY actions to take to ensure that this project is successful?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relevant Codes of Practice}
Professional codes of conduct provide software engineers with an ethical starting point for a deployment of this nature.
Given the bandwidth of this topic, and the scope of this report, exhaustive coverage of the full documentation is impossible, so key characteristics of differing guidelines will be the primary focal point.
The BCS focusses on professionals; the IEEE standardises the technological aspects; the ACM is more concerned with societal impact.

\subsection{BCS Code of Conduct}
BCS members must demonstrate "due regard for public health, privacy, security and wellbeing of others and the environment" \textit{\parencite[p. 2]{BCS2024}}, particularly salient considering `Alice' will be handling sensitive student data and potentially influencing student wellbeing.

The BCS also mandates professionals to only provide service "within [their] professional competence" \textit{\parencite[p. 2]{BCS2024}}, which begs the question: where exists the limit of `Alice''s 'competence' in the context of student support?
Is a system's competency assumed to be an extension of the professionals who calibrated it?

Members are additionally required to "uphold the reputation of the profession" \textit{\parencite[p. 3]{BCS2024}}.
This translates to full transparency regarding `Alice''s management and capabilities.
Safeguards must also be in place to prevent misuse in order to preserve public trust of AI systems in education, let alone the trust of students.

\subsection{IEEE Code of Ethics}
Data retention and deletion policies must be established and clear, ensuring a commitment to "protection of... personal information and data" \textit{\parencite[p. 1]{IEEE2024}}, and a commitment to student privacy.
Engineers must identify and eliminate potential bias from the model and algorithms in use, such that `Alice' "not discriminate against any person because of characteristics protected by law" \textit{\parencite[p. 1]{IEEE2024}}.
This should be verified and assured with rigorous testing and regular audits, ensuring commitment to "honest and realistic... claims or estimates based on available data" \textit{\parencite[p. 2]{IEEE2024}}, coupled with an established mechanism for human oversight and intervention when `Alice''s confidence in a response is low.

\subsection{ACM Code of Ethics}
The ACM Code proposes that "all people are stakeholders in computing" \textit{\parencite[p. 1]{ACM2024}}, alluding that the enhancement of student wellbeing and academic success is not merely a nice gesture, but necessary for the betterment of society, assuming compliant (and considerate) execution.

`Alice' should be constructed with accessibility in mind, "[fostering] fair participation of all people, including those of underrepresented groups" \textit{\parencite[p. 2]{ACM2024}}.

\subsubsection*{Caveats to Information Processing}
Blundell argues that "such codes are seldom consulted and often incorporate bland (and sometimes contradictory) statements intended to satisfy a broad range of stakeholders" \textit{\parencite[p. 40]{Blundell2020}} and professionals must practise discernment and maintain awareness for the consequences of poor decision-making, both quantitatively and in qualitative aspects.
Underpinning deontological ethics is the notion that the professional is duty-bound to rely on their better judgement where universally established rules fail.
Duty to reason is one of the core beliefs that make up Kant's philosophical tenet, "respect the reason in you."

The BCS specifies duty to "due... diligence in accordance with the Relevant Authority's requirements whilst exercising... professional judgement at all times" \textit{\parencite[p. 2]{BCS2024}}.
In context: information relating to the endangerment of any student(s) takes precedent over privacy, as is established protocol \textit{in loco parentis}, at the discretion of human moderators.
Sophisticated content-flagging and de-identification secured by multiple key-holders will ensure awareness and consensus for de-anonymisation.
Students may be more comfortable anonymously, so this process of de-anonymising must be abuse-proof to ensure trust remains strong.

All decision-making processes must prioritise students foremost, with the necessary privacy precautions in place to protect student data alongside regular monitoring of the chatbot's holistic impact on the educational environment.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Further Considerations}

\subsubsection*{A Note on Regulatory Standards}
In-depth representation for truly ethical and compliant practice are appended in Appendix \ref{appendix:b} (relevant definitions with respect to implications for `Alice'), and not the main body of this report, for brevity's sake.

\subsection{Ethical Data Governance}
Any implementation of `Alice' would raise significant privacy concerns regarding the collection, storage, and use of student data \textit{\parencite[pp. 366-370]{Annus2023}}. In the best interest of both students and the law, all-encompassing singular actions, policies, and processes have the potential to satisfy the needs of all stakeholders simultaneously.
Proper management of data involves:

\subsubsection{GDPR/Regulatory Compliance}
From design through to deployment continuously for any collection of data, as well as full transparency in its use of data, and clarity regarding what it is collecting data to be used for, TechSoft must define the nature of its policies, processes, and practice.
It is also imperative that TechSoft safeguard against any third-parties from gaining access to data with security best practices.
Schools are in position to safeguard student data, appreciating this perspective is essential for TechSoft engineers.
For more information, see Appendix \ref{appendix:b}.
Additionally, record a Data Protection Impact Assessment (DPIA) and keep it up to date (template provided in Appendix \ref{appendix:a}).

\subsubsection{Data Security}
Privacy by design as an ethos enabling strong governance and security measures;
OAuth 2.0 and OpenID Connect for Single Sign-On (SSO) and Role-Based Access Control (RBAC) for fine-tuning permissions \textit{\parencite[pp. 80-120]{Josuttis2023}}.
Data encryption \textit{\parencite[pp. 100-150]{Stallings2023}}, AES-256 for data at rest and TLS 1.3 for data in transit.

\subsubsection{Data Anonymisation}
K-anonymity employed for protecting student identities \textit{\parencite[pp. 75-100]{ElEmamArbuckle2023}}, and the implementation of differential privacy for aggregate data analysis, anonymising students entirely into statistics beneficial for upgrading and improving the chatbot, and alleviating the burden of at-risk data unnecessary for development purposes.

\subsubsection{Data Minimisation}
Data "audited regularly to ensure all stored information is still relevant" \textit{\parencite{A29WP2018}}, implementing "privacy-preserving UX patterns" \textit{\parencite[pp. 50-100]{Hartzog2023}}, making privacy settings easily accessible and understandable.

\subsubsection{Informed Consent}
Information about data usage must be clear, with opt-in mechanisms for non-essential features.
Age-appropriate consent must be obtained from students (parental consent for students under the age of 13 \textit{\parencite{FTC2023}}).

\subsection{AI Ethics Principles}
Principled practice is a must, adhering to established AI ethics principles \textit{\parencite{EC2024}}:

\subsubsection{Ethical Algorithm Design}
Explicit labelling of `Alice' as an AI system \textit{\parencite{IEEE2023}}, prioritising the elucidation of users.
Understanding algorithmic configuration choices and their consequences can benefit not only developers, but users, and by extension society en masse.

\subsubsection{Human Agency and Oversight}

Setting "clear boundaries between AI support and human intervention" \textit{\parencite{APA2024}} by defining thresholds for transitioning between human support and AI.
Contextual enquiry of staff to better map support scenarios by conducting user research \textit{\parencite[pp. 50-100]{Goodman2023}}, alongside human-in-the-loop dialogue optimisation \textit{\parencite[pp. 30-60]{Vaughan2024}}.
Evaluations can be crowdsourced for diverse perspectives.

\subsubsection{Iterative Design Process}
An iterative strategy \textit{\parencite[pp. 30-60]{HoltzblattBeyer2024}} will aid in the formation of an adaptable system for frequent ethical review \textit{\parencite{FloridiCowls2023}}.
Periodic assessment of chatbot bias, plus alignment against ethical benchmarks.
Usability testing with representative student groups ensures these needs are measured and met on a regular basis.

\subsubsection{Disinformation and Technical Safety}
Content-filtering in effect, with established escalation protocols for disinformation or harmful content.
Natural and effective chatbot interactions, establishing tone and personality \textit{\parencite[pp. 20-50]{Bradbury2024}}, maintaining a consistent voice aligned with an educational context, ensuring age-appropriate content.
Harmful or inappropriate chatbot responses \textit{\parencite[p. e11510]{Bickmore2021}} accounted for.

\subsubsection{Transparency}
 "Explainable AI techniques to interpret chatbot decisions" \textit{\parencite[pp. 82-115]{Arrieta2022}} thanks to interpretable machine learning models and provision of rationale, with respect to design recommendations in the software lifecycle.


 \subsubsection{Fairness-Aware Machine Learning}
"Fairness-aware machine learning" technology \textit{\parencite{Barocas2021}}, tracking algorithm parity fairness metrics.
    TechSoft must subsume a mindset for mitigation: frequent bias testing, essential for equitable support.
Regular bias testing \textit{\parencite{ACMFAccT2024}} including the employment of automated bias-detection tools, in tandem with supervised evaluation.

Diverse training data, to prevent demographic biases \textit{\parencite[pp. 1-35]{Mehrabi2023}} is important.
Diverse student profiles in training data ensure an inclusive model representative of the entire student demographic.


\subsection{Ethical UX Design Patterns}
TechSoft must commit to a design process focussed on student needs:

\subsubsection{Accessibility Standards}
Adhering to WCAG 2.2 \textit{\parencite{W3C2023}}, content can be perceivable, operable, understandable, and considerate of an array of user interaction.

Cognitive accessibility \textit{\parencite[pp. 1-10]{Yesilada2023}} with clear and simple language, alongside multi-lingual options \textit{\parencite[pp. 50-100]{AnastasiouSchaler2023}} provides consistent layout and interaction patterns.

\subsubsection{User-Centred Design}
An adaptable user interface \textit{\parencite[pp. 20-50]{HarperYesilada2024}}, offering customisable font sizes and colour contrasts supporting a range of input (text, voice, video, gestures), and optionally reducing visual clutter to address neurodiversity \textit{\parencite[pp. 30-60]{Armstrong2023}} will accommodate special needs.

\subsubsection{Dark Pattern Avoidance}
Dark patterns \textit{\parencite{Brignull2023}} must be avoided.
Operational transparency including information about `Alice' and data usage, with clear opt-out options for data collection are of utmost importance.
Information pertinent to students and their rights must be made crystal clear.

\subsubsection{Attention Economy Awareness}
This includes also addressing attention economy concerns \textit{\parencite[pp. 10-30]{Williams2024}}, designing for focussed, purposeful interactions and avoiding addictive design patterns.
This is vital in the context of impressionable and susceptible youth and vulnerable persons.

\subsubsection{Psychological Impact}
AI Support is liable to psychological impacts as well and these must be considered  too.
TechSoft must mitigate the risk of over-reliance on AI for emotional support \textit{\parencite[p. 746]{Miner2022}}, clearly communicating AI's role as a supplement to (not replacement for) human support.
Pre-existing human counselling services can be integrated facilitating non-AI support roles.

\subsection{Monitoring, Evaluation, and Continuous Improvement}
 "Human-centric AI" should be a key principle.
 TechSoft should co-opt a model of supervised learning for classification tasks (e.g., identifying at-risk students) with the following tools:

\subsubsection{Natural Language Processing (NLP) Frameworks}
A state-of-the-art chatbot implementation may employ a GPT/Transformer-based, or even BERT model, implementing NLP frameworks \textit{\parencite[pp. 1-15]{JurafskyMartin2024}} simulating an understanding of context and intent in a bespoke service.

\subsubsection{Conversational Metrics}
Setting up telemetry \textit{\parencite[pp. 30-60]{Vadapalli2023}} includes real-time data collection on user interactions, ensuring privacy-preserving logging mechanisms. Once established, however, is an incredibly utile toolchain for measuring conversational metrics \textit{\parencite[pp. 1-32]{Quarteroni2024}}.
Enabling response accuracy and relevance, and task completion rates, to be tracked in real-time.


\subsubsection{Usage Analytics}
Common queries and pain points can be identified with usage analytics \textit{\parencite[pp. 50-100]{Beasley2023}}, analysing conversation flows and quality.
Sentiment analysis \textit{\parencite[pp. 50-100]{Liu2023}} can be performed, analysing emotional tone of student interactions.

\subsubsection{Research Collaboration}
    It would be beneficial to foster the academic community, establishing partnerships with universities \textit{\parencite[pp. 50-100]{Dillenbourg2023}} for contribution to research, and ensuring the quality of the service.
    Findings can also be published to contribute to the broader field.

\end{multicols}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Reflection and Recommendations}
Throughout the software development lifecycle, encapsulated here: "privacy by design" from the foundation, with "human-centric AI" as a guiding principle to instill responsibility and a "mindset for mitigation."
With ethos-driven targets permeating every aspect of its implementation, `Alice' must also exemplify educational empowerment for cognitive stewardship.Devise training for staff to work effectively alongside AI systems, not in lieu of them, all the while maintaining accountability as protocol.
Transparency can ensure TechSoft a model for "responsible innovation" in educational AI and amongst a sensitive and valued ecology of academia.
Compliance, accessibility, and effectiveness will converge naturally through thoughtful design choices to establish a sensible and proactive ethical framework and governance structure.
In combination with adaptive and continuous evaluation, TechSoft can assure a system that truly serves its mission while protecting student interests.
Prioritise students. Cater to diverse student needs.
Ensure continued compliance with legislature.
Complete and maintain an updated Data Protection Impact Assessment, filing and refactoring it according to a robust change policy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Appendix A: Data Protection Impact Assessment Template}\label{appendix:a}

\begin{multicols}{2}
\subsection*{1. Project Overview}
\begin{itemize}
  \item \textbf{Project Name:} AI Chatbot in Education
    \item \textbf{Data Controller:} South Star Academy
    \item \textbf{System Owner:} TechSoft
      %most recent date
    \item \textbf{Date of Latest Revision:}
\end{itemize}

\subsection*{2. Data Processing Activities}
\begin{enumerate}
    \item \textbf{Nature of Processing}
    \begin{itemize}
        \item Collection methods
        \item Data flows
        \item Retention period and procedure
    \end{itemize}

    \item \textbf{Scope of Processing}
    \begin{itemize}
        \item Types of personal data processed
        \item Volume, aims and scope
        \item Context of processing
    \end{itemize}
\end{enumerate}

\subsection*{3. Necessity and Proportionality}

\begin{enumerate}
  \item \textbf{Lawful Basis for Processing}

\begin{itemize}
    \item Identify relevant Article 6 GDPR condition
    \item Identify Article 9 condition
    \item Justification for chosen basis
\end{itemize}

  \item \textbf{Data Minimisation}
\begin{itemize}
    \item Justification for each data element
    \item Retention periods and rationale
    \item Privacy-preserving measures
\end{itemize}
  \item \textbf{Accuracy Measures}
    \begin{itemize}
        \item Data quality procedures
        \item Update mechanisms
        \item Verification processes
    \end{itemize}
\end{enumerate}

\end{multicols}

\subsection*{4. Risk Assessment}
\begin{longtable}{|p{3cm}|p{4cm}|p{3cm}|p{3cm}|}
    \hline
    \textbf{Risk} & \textbf{Potential Impact} & \textbf{Likelihood (H/M/L)} & \textbf{Mitigation Measures} \\
    \hline
    Data Breach & Unauthorised access to student data & H &  \\
    \hline
    Algorithm Bias & Unfair treatment of certain student groups & M &  \\
    \hline
    Mental Health Impact & Negative psychological effects from AI interactions & M &  \\
    \hline
    Data Accuracy & Incorrect support guidance & M &  \\
    \hline
    System Misuse & Exploitation of AI system & M &  \\
    \hline
\end{longtable}

\vspace{0.5em}
\begin{multicols}{2}
\subsection*{5. Data Subject Rights}
\begin{enumerate}
    \item \textbf{Information Provision}
    \begin{itemize}
        \item Privacy notice content
        \item Rectification and erasure mechanisms
    \end{itemize}
\end{enumerate}

\subsection*{6. Organisational Measures}
\begin{enumerate}
    \item \textbf{Security Standards}
    \begin{itemize}
        \item Network security
        \item Physical security
        \item Staff training
    \end{itemize}

    \item \textbf{Data Protection Measures}
    \begin{itemize}
        \item Data minimisation controls
        \item Purpose limitation safeguards
    \end{itemize}
\end{enumerate}

\subsection*{7. Consultation}
\begin{enumerate}
    \item \textbf{Internal Stakeholders}
    \begin{itemize}
        \item IT Security Team feedback
        \item Legal Team review
        \item Student Support Services input
        \item Senior Management approval
    \end{itemize}

    \item \textbf{External Stakeholders}
    \begin{itemize}
        \item Student representative feedback
        \item Parent consultation
        \item Educational authority guidance
        \item DPO recommendations
    \end{itemize}
\end{enumerate}
\end{multicols}

\subsection*{8. Risk Treatment}
\begin{longtable}{|p{4cm}|p{4cm}|p{4cm}|}
    \hline
    \textbf{Identified Risk} & \textbf{Treatment Measure} & \textbf{Residual Risk Level} \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
\end{longtable}


\begin{enumerate}
    \item \textbf{Outcome Decision}
    \begin{itemize}
      \item Proceed with processing: (Y) / (N)
        \item Conditions applied:
    \end{itemize}
\end{enumerate}

\vspace{0.5em}

\subsection*{9. Ongoing Monitoring Plan}
\begin{enumerate}
    \item \textbf{Review Schedule}
    \begin{itemize}
        \item Regular review dates
        \item Trigger events for review
        \item Responsibility assignments
    \end{itemize}

    \item \textbf{Monitoring Measures}
    \begin{itemize}
        \item Performance metrics
        \item Incident reporting
        \item Audit procedures
    \end{itemize}
\end{enumerate}

\vspace{12em}

\subsection*{10. Sign-off}

Information Security Manager:

\vspace{2cm}
\noindent\makebox[8cm]{\hrulefill}
\vspace{0.2cm}
\\\noindent Signature:


\newpage

\section{Appendix B: Regulatory Standards}\label{appendix:b}

\subsection*{DATA PROTECTION LEGISLATION}

\subsubsection*{General Data Protection Regulation (GDPR)}
"
\begin{itemize}
    \item Establishing a lawful basis for processing: Consent or legitimate interests
    \item Implementing data subject rights: Access, rectification, erasure, portability
    \item Appointing a Data Protection Officer (DPO)
\end{itemize}
"

\textit{\parencite{EU2016}}

\subsubsection*{UK Data Protection Act 2018}
"
\begin{itemize}
    \item Adhering to specific provisions for processing personal data in educational contexts
    \item Implementing safeguards for processing special category data (e.g., health information)
\end{itemize}
"

\textit{\parencite{UKGov2018}}:

\subsubsection*{Children's Online Privacy Protection Act (COPPA)}
"
\begin{itemize}
    \item Obtaining parental consent for students under 13
    \item Implementing limited data collection and retention policies
\end{itemize}
"


\textit{\parencite{FTC2023}}

\subsection*{EDUCATION SECTOR REGULATIONS}

\subsubsection*{Education and Skills Act 2008}
"
\begin{itemize}
    \item Fulfilling the duty to promote the well-being of students
    \item Implementing safeguarding responsibilities in digital environments
\end{itemize}
"

\textit{\parencite{UKGov2008}}


\subsubsection*{Keeping Children Safe in Education}
"
\begin{itemize}
    \item Implementing online safety measures for educational technology
    \item Providing staff training on digital safeguarding
\end{itemize}
"

\textit{\parencite{DfE2024a}}

\subsubsection*{Special Educational Needs and Disability (SEND) Code of Practice}
"
\begin{itemize}
    \item Ensuring accessibility requirements for digital learning tools are met
    \item Considering personalised support for students with SEND
\end{itemize}
"

\textit{\parencite{DfE2024b}}


\subsection*{PROFESSIONAL STANDARDS AND GUIDELINES}

\subsubsection*{BCS Code of Conduct}
"
\begin{itemize}
    \item Considering public interest in development decisions
    \item Maintaining professional competence and integrity
    \item Fulfilling duty to relevant authorities
\end{itemize}
"

\textit{\parencite[pp. 1-5]{BCS2024}}


\subsubsection*{ACM Code of Ethics and Professional Conduct}
"
\begin{itemize}
    \item Contributing to society and human well-being
    \item Avoiding harm in system design and implementation
    \item Maintaining honesty and trustworthiness
\end{itemize}
"

\textit{\parencite[pp. 1-4]{ACM2024}}

\subsubsection*{IEEE Ethically Aligned Design}
"
\begin{itemize}
    \item Preserving human rights in AI systems
    \item Ensuring transparency and accountability in AI decision-making
    \item Implementing privacy-by-design principles
\end{itemize}
"

\textit{\parencite[pp. 2-5]{IEEE2024}}


\subsection*{INDUSTRY-SPECIFIC STANDARDS}

\subsubsection*{ISO/IEC 27001:2022}
"
\begin{itemize}
    \item Conducting risk assessment and management
    \item Implementing information security controls
    \item Establishing continuous improvement processes
\end{itemize}
"

\textit{\parencite{ISO2022}}


\subsubsection*{Learning Tools Interoperability (LTI) Standards}
"
\begin{itemize}
    \item Ensuring secure integration with existing learning management systems
    \item Enabling data portability and interoperability
\end{itemize}
"

\textit{\parencite{IMSGlobal2024}}


\subsubsection*{Web Content Accessibility Guidelines (WCAG) 2.2}
"
\begin{itemize}
    \item Ensuring the chatbot interface is perceivable, operable, understandable, and robust
    \item Maintaining compatibility with assistive technologies
\end{itemize}
"

\textit{\parencite{W3C2023}}

\subsection*{ETHICAL AI FRAMEWORKS}

\subsubsection*{UNESCO Recommendation on the Ethics of Artificial Intelligence}
"
\begin{itemize}
    \item Protecting human rights and fundamental freedoms
    \item Promoting diversity and inclusiveness in AI systems
    \item Ensuring transparency and explainability of AI decisions
\end{itemize}
"

\textit{\parencite{UNESCO2021}}

\subsubsection*{OECD AI Principles}
"
\begin{itemize}
    \item Ensuring AI benefits people and the planet
    \item Designing AI systems that respect the rule of law, human rights, democratic values, and diversity
\end{itemize}
"

\textit{\parencite{OECD2023}}

\subsubsection*{EU Ethics Guidelines for Trustworthy AI}
"
\begin{itemize}
    \item Implementing human agency and oversight in AI systems
    \item Ensuring technical robustness and safety
    \item Maintaining privacy and data governance
\end{itemize}
"

\textit{\parencite{EC2024}}

\subsection*{CONTINUOUS COMPLIANCE/ONGOING AUDITING IN PERPETUITY}

\subsubsection*{Regular Compliance Audits}
"
\begin{itemize}
    \item Performing annual data protection audits
    \item Engaging third-party security assessments
\end{itemize}
"

\textit{\parencite{ICO2024}}

\subsubsection*{Continuous Professional Development}
"
\begin{itemize}
    \item Providing regular training on evolving legal and ethical standards
    \item Obtaining certification in AI ethics for key personnel
\end{itemize}
"

\textit{\parencite{CIPD2024}}


\newpage

\printbibliography


\end{document}
