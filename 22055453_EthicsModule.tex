\documentclass[14pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[style=authoryear,backend=biber]{biblatex}
\DeclareDelimFormat{postnotedelim}{\addcomma\space}
\usepackage{csquotes}
\usepackage[margin=2.5cm]{geometry}
\usepackage{titlesec}
\usepackage{appendix}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{fancyhdr}
\usepackage{xurl}
\usepackage{multicol}

\addbibresource{references.bib}

\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}

  \title{Report and Recommendations\\ `Alice' \\ Ethical Considerations for AI in Education}
\author{Enzo Joly, 22055453}
\date{}


\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{TechSoft Internal Report: Ethical Considerations for Development of Alice}
\fancyhead[R]{Page \thepage}
\fancyfoot[C]{\thepage}

\begin{document}

\maketitle

\hrule

\vspace{3em}

Module Title: UFCFB5-15-3 | Ethical and Professional Issues in Computing and Digital Media

Word Count: 2,069

\vspace{3em}
\hrule

\vspace{2em}
\textbf{\Large{Abstract: Executive Summary}}

\begin{center}
\textbf{Ethical and/or Social Issues Important for this Project}
\end{center}

%The implementation of Alice presents several critical ethical and social considerations that must be carefully addressed. Student privacy and data protection emerge as paramount concerns, given the sensitive nature of educational and personal information being processed. The risk of algorithmic bias could potentially lead to unfair treatment or support disparities among different student groups. There are also significant considerations around the psychological impact of AI-supported student services, including the risk of over-reliance on automated support systems. The project must balance technological innovation with maintaining human connection in educational support, ensuring that AI augments rather than replaces human interaction. Additionally, accessibility and inclusivity requirements must be met to serve a diverse student population effectively.

- Student data protection and privacy measures, prioritising students and legal compliance.

- Recognition and mitigation of algorithmic bias risks that may create unfair treatment.

- Consideration of psychological impacts stemming from AI-supported student services.

- Appropriate human-AI interaction boundaries within an educational support services context.

- Prevention of over-reliance on automated systems and maintaining meaningful human connections.

- Implementation of comprehensive accessibility features to support diverse student requirements.

- Maintenance of ethical standards throughout educational support provision.

- Steadfast protection of student wellbeing as the paramount consideration.

\begin{center}
\textbf{Professional, Legal \& Design Standards for Implementation}
\end{center}

%The project requires adherence to multiple regulatory frameworks and professional standards. The GDPR and UK Data Protection Act 2018 provide essential guidelines for data handling and privacy protection. Educational sector-specific regulations, including the Education and Skills Act 2008 and the SEND Code of Practice, establish requirements for student wellbeing and accessibility. Professional standards from organizations like the BCS, IEEE, and ACM offer ethical frameworks for AI implementation. The Web Content Accessibility Guidelines (WCAG) 2.2 ensures inclusive design, while ISO/IEC 27001:2022 provides information security management standards. Industry-specific frameworks such as the UNESCO Recommendation on the Ethics of AI and the EU Ethics Guidelines for Trustworthy AI offer additional guidance for ethical AI deployment in educational contexts.

- GDPR and UK Data Protection Act 2018 frameworks for data handling.

- Education and Skills Act 2008 requirements met for educational provision.

- SEND Code of Practice guidelines integrated for special educational needs.

- Professional standards from BCS, IEEE, and ACM adopted for ethical AI implementation.

- Adherence to WCAG 2.2 guidelines ensuring the product meets digital accessibility standards.

- ISO/IEC 27001:2022 protocols and standards adhered to for information security management.

- UNESCO AI Ethics frameworks integrated for international best practice.

- EU Trustworthy AI guidelines adhered to for ethical implementation standards.



\begin{center}
\textbf{Key Actions and Features to be Implemented for Project Success}
\end{center}

%To ensure successful implementation, several critical actions must be undertaken. First, establish a comprehensive data governance framework incorporating privacy by design principles and regular security audits. Implement robust consent mechanisms and clear data minimization policies. Develop a systematic approach to bias testing and mitigation, including diverse training data and regular algorithmic audits. Create clear escalation protocols for situations requiring human intervention, and establish boundaries between AI and human support. Deploy accessibility features that accommodate various learning needs and disabilities. Institute continuous monitoring and evaluation systems to track the chatbot's impact on student wellbeing and academic success. Provide thorough staff training on working alongside AI systems and maintaining accountability. Finally, maintain transparent communication with all stakeholders about the system's capabilities and limitations, fostering trust and responsible innovation in educational AI.

- Privacy-by-design governance frameworks incorporating GDPR and educational sector requirements.

- Informative consent-based mechanisms and provisions for parental consent and student data rights.

- Multi-layered bias testing protocols using diverse training data, representative of demographics.

- Creation of detailed escalation pathways that define precise thresholds for human intervention.

- Accessibility features aligned with WCAG 2.2 standards, including support of diverse learning needs.

- Sophisticated natural language processing frameworks that ensure age-appropriate interactions.

- Secure data handling compliant with both ISO/IEC 27001:2022 and educational sector requirements.

- Continuous monitoring systems that track performance and impact. Iterative development.

- Audit trails tracking system decisions and human interventions whilst maintaining student anonymity.

- Thorough staff training programmes covering both technical operation and ethical considerations.

- Documentation supporting continuous improvement and knowledge-sharing.

\vspace{3em}
\hrule




\thispagestyle{empty}

\newpage

\tableofcontents
\pagenumbering{roman}

\newpage

\pagenumbering{arabic}

\begin{multicols}{2}
\section{Introduction}
This report comprises ethical considerations and analysis concerning technology, data privacy, disinformation, and accessibility.

The resulting recommendations for deployment aim to inform, such that TechSoft be fully cognisant of challenges faced by an AI chatbot in education.
South Star Academy's proposed student support services chatbot `Alice' will require thoughtful diligence before it can be deemed production-ready.

%Public Interest
%Data Governance Policy
%Escalation Policy

%What ethical or social issues are important for this project?

%What professional, legal or design standards might the organisation need to read and implement?

%What can YOU suggest as KEY actions to take to ensure that this project is successful?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relevant Codes of Practice}
Professional codes of conduct provide software engineers with an ethical starting point for a deployment of this nature.
Given the bandwidth of this topic, and the scope of this report, exhaustive coverage of the full documentation is impossible, so key characteristics of differing guidelines will be the primary focal point.
The BCS focusses on professionals; the IEEE standardises the technological aspects; the ACM is more concerned with societal impact.

\subsection{BCS Code of Conduct}
BCS members must demonstrate "due regard for public health, privacy, security, and wellbeing of others and the environment" \textit{\parencite[p. 2]{BCS2024}}, particularly salient considering Alice will be handling sensitive student data and potentially influencing student wellbeing.

The BCS also mandates professionals to only provide service "within [their] professional competence" \textit{\parencite[p. 2]{BCS2024}}, which begs the question: where exists the limit of Alice's `competence' in the context of student support?
Is a system's competency assumed to be an extension of the professionals who calibrated it?

Members are additionally required to "uphold the reputation of the profession" \textit{\parencite[p. 3]{BCS2024}}.
This translates to full transparency regarding Alice's management and capabilities.
Safeguards must also be in place to prevent misuse in order to preserve public trust of AI systems in education, let alone the trust of students.

\subsection{IEEE Code of Ethics}
Data retention and deletion policies must be established and clear, ensuring a commitment to "protection of... personal information and data" \textit{\parencite[p. 1]{IEEE2024}}, and a commitment to student privacy.
Engineers must identify and eliminate potential bias from the model and algorithms in use, such that Alice "not discriminate against any person because of characteristics protected by law" \textit{\parencite[p. 1]{IEEE2024}}.
This should be verified and assured with rigorous testing and regular audits, ensuring commitment to "honest and realistic... claims or estimates based on available data" \textit{\parencite[p. 2]{IEEE2024}}, coupled with an established mechanism for human oversight and intervention when Alice's confidence in a response is low.

\subsection{ACM Code of Ethics}
The ACM Code proposes that "all people are stakeholders in computing" \textit{\parencite[p. 1]{ACM2024}}, alluding that the enhancement of student wellbeing and academic success is not merely a nice gesture, but necessary for the betterment of society, assuming compliant (and considerate) execution.

Alice should be constructed with accessibility in mind, "[fostering] fair participation of all people, including those of underrepresented groups" \textit{\parencite[p. 2]{ACM2024}}.

\subsubsection*{Caveats to Information Processing}
Blundell argues that "such codes are seldom consulted and often incorporate bland (and sometimes contradictory) statements intended to satisfy a broad range of stakeholders" \textit{\parencite[p. 40]{Blundell2020}} and professionals must practise discernment and maintain awareness for the consequences of poor decision-making, both quantitatively and in qualitative aspects.
Underpinning deontological ethics is the notion that the professional is duty-bound to rely on their better judgement where universally established rules fail.
Duty to reason is one of the core beliefs that make up Kant's philosophical tenet: "respect the reason in you."

The BCS specifies duty to "due... diligence in accordance with the Relevant Authority's requirements whilst exercising... professional judgement at all times" \textit{\parencite[p. 2]{BCS2024}}.
In context: information relating to the endangerment of any student(s) takes precedent over privacy, as is established protocol \textit{in loco parentis}, at the discretion of human moderators.
Sophisticated content-flagging and de-identification secured by multiple key-holders will ensure awareness and consensus for de-anonymisation.
Students may be more comfortable anonymously, so this process of de-anonymising must be abuse-proof to ensure trust remains strong.

All decision-making processes must prioritise students foremost, with the necessary privacy precautions in place to protect student data alongside regular monitoring of the chatbot's holistic impact on the educational environment.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Further Considerations}

%\subsubsection*{A Note on Regulatory Standards}
%In-depth representation for truly ethical and compliant practice are appended in Appendix \ref{appendix:b} (relevant definitions with respect to implications for Alice), and not the main body of this report, for brevity's sake.

\subsection{Ethical Data Governance}
Any implementation of Alice would raise significant privacy concerns regarding the collection, storage, and use of student data \textit{\parencite[pp. 366-370]{Annus2024}}. In the best interest of both students and the law, all-encompassing singular actions, policies, and processes have the potential to satisfy the needs of all stakeholders simultaneously.
Proper management of data involves:

\subsubsection{GDPR/Regulatory Compliance}
From design through to deployment continuously for any collection of data, as well as full transparency in its use of data, and clarity regarding what it is collecting data to be used for, TechSoft must define the nature of its policies, processes, and practice.
It is also imperative that TechSoft safeguard against any third-parties from gaining access to data with security best practices.
Schools are in position to safeguard student data, appreciating this perspective is essential for TechSoft engineers.
For more information, see Appendix \ref{appendix:b}.
Additionally, record a Data Protection Impact Assessment (DPIA) and keep it up to date (template provided in Appendix \ref{appendix:a}).

\subsubsection{Data Security}
Privacy by design as an ethos enabling strong governance and security measures;
OAuth 2.0 and OpenID Connect for Single Sign-On (SSO) and Role-Based Access Control (RBAC) for fine-tuning permissions \textit{\parencite[pp. 80-120]{Josuttis2024}}.
Data encryption \textit{\parencite[pp. 100-150]{Stallings2024}}, AES-256 for data at rest and TLS 1.3 for data in transit.

\subsubsection{Data Anonymisation}
K-anonymity employed for protecting student identities \textit{\parencite[pp. 75-100]{ElEmamArbuckle2024}}, and the implementation of differential privacy for aggregate data analysis, anonymising students entirely into statistics beneficial for upgrading and improving the chatbot, and alleviating the burden of at-risk data unnecessary for development purposes.

\subsubsection{Data Minimisation}
Information about data usage must be clear, facilitating informed consent.
The EU mandates that "only the minimum amount of personal data necessary for each specific purpose of processing should be processed" \textit{\parencite{EU2016}}.
The potential consequences of over-collection include impeding student rights, while under-collection poses the risk of stagnation - a significantly more manageable dilemma.
One key challenge will be defining what `minimum necessary' data entails.
In this context, it is even more vital to ensure that data is only collected when necessary, and that it is stored securely and "audited regularly to ensure all stored information is still relevant" \textit{\parencite{A29WP2018}}, implementing "privacy-preserving UX patterns" \textit{\parencite[pp. 50-100]{Hartzog2024}}, making privacy settings easily accessible and understandable.
There will be no equivalent mitigation for breaches of trust, so it is of paramount importance that TechSoft maintain a high standard of data governance.

\subsection{AI Ethics Principles}
Explicit labelling of Alice as an AI system \textit{\parencite{IEEE2024}}, prioritising the elucidation of users.
Understanding algorithmic configuration choices and their consequences can benefit not only developers, but users, and by extension society \textit{en masse}.
Principled practice is a must, adhering to established AI ethics principles \textit{\parencite{EC2024}}:

\subsubsection{Human Agency and Oversight}

Setting "clear boundaries between AI support and human intervention" \textit{\parencite{APA2024}} by defining thresholds for transitioning between human support and AI.
Contextual enquiry of staff to better map support scenarios by conducting user research \textit{\parencite[pp. 50-100]{Goodman2024}}, alongside human-in-the-loop dialogue optimisation \textit{\parencite[pp. 30-60]{Vaughan2024}}.
Evaluations can be crowdsourced for diverse perspectives.

\subsubsection{Iterative Design Process}
An iterative strategy \textit{\parencite[pp. 30-60]{HoltzblattBeyer2024}} will aid in the formation of an adaptable system for frequent ethical review \textit{\parencite{FloridiCowls2024}}.
Periodic assessment of chatbot bias, plus alignment against ethical benchmarks.
Usability testing with representative student groups ensures these needs are measured and met on a regular basis.

\subsubsection{Disinformation and Technical Safety}
Content-filtering in effect, with established escalation protocols for disinformation or harmful content.
Natural and effective chatbot interactions establish tone and personality \textit{\parencite[pp. 20-50]{Bradbury2024}}, maintaining a consistent voice aligned with an educational context, and ensuring age-appropriate content.
Harmful or inappropriate chatbot responses \textit{\parencite[p. e11510]{Bickmore2021}} accounted for.

\subsubsection{Fairness-Aware Transparency}
 "Explainable AI techniques to interpret chatbot decisions" \textit{\parencite[pp. 82-115]{Arrieta2022}} thanks to interpretable machine learning models and provision of rationale, with respect to design recommendations in the software lifecycle.
"Fairness-aware machine learning" technology \textit{\parencite{Barocas2021}}, tracking algorithm parity fairness metrics.
    TechSoft must subsume a mindset for mitigation: frequent bias testing, essential for equitable support.
%Regular bias testing \textit{\parencite{ACMFAccT2024}} including the employment of automated bias-detection tools, in tandem with supervised evaluation.

Diverse training data, to prevent demographic biases \textit{\parencite[pp. 1-35]{Mehrabi2024}} is important.
Diverse student profiles in training data ensure an inclusive model representative of the entire student demographic.


\subsection{Ethical UX Design Patterns}
TechSoft must commit to design focussed on student needs:

\subsubsection{Accessibility Standards}
Adhering to WCAG 2.2 \textit{\parencite{W3C2024}}, content can be perceivable, operable, understandable, and considerate of an array of user interaction.

Cognitive accessibility \textit{\parencite[pp. 1-10]{Yesilada2024}} with clear and simple language, alongside multi-lingual options \textit{\parencite[pp. 50-100]{AnastasiouSchaler2024}} provides consistent layout and interaction patterns.

\subsubsection{User-Centred Design}
An adaptable user interface \textit{\parencite[pp. 20-50]{HarperYesilada2024}} offering customisable font sizes/colour contrasts, supporting a range of input (text, voice, video, and gestures), reducing visual clutter to address neurodiversity \textit{\parencite[pp. 30-60]{Armstrong2024}}, and accommodating special needs.

\subsubsection{Dark Pattern Avoidance}
Dark patterns \textit{\parencite{Brignull2024}} must be avoided.
Operational transparency including information about Alice and data usage, with clear opt-out options for data collection are of utmost importance.
Information pertinent to students and their rights must be made crystal clear.

\subsubsection{Attention Economy Awareness}
This includes also addressing attention economy concerns \textit{\parencite[pp. 10-30]{Williams2024}}, designing for focussed, purposeful interactions and avoiding addictive design patterns.
This is vital in the context of impressionable and susceptible youth and vulnerable persons.

\subsubsection{Psychological Impact}
%AI Support is liable to psychological impacts as well and these must be considered  too.
TechSoft must mitigate the risk of over-reliance on AI for emotional support \textit{\parencite[p. 746]{Miner2022}}, clearly communicating AI's role as a supplement to (not replacement for) human support.
Pre-existing human counselling services can be integrated facilitating non-AI support roles.

\subsection{Monitoring, Evaluation, and Continuous Improvement}
 "Human-centric AI" should be a key principle.
 TechSoft should co-opt a model of supervised learning for classification tasks (e.g., identifying at-risk students) with the following tools:

\subsubsection{Natural Language Processing (NLP) Frameworks}
A state-of-the-art chatbot implementation may employ a transformer-based (or alternative) architecture model, implementing NLP frameworks \textit{\parencite[pp. 1-15]{JurafskyMartin2024}} to simulate an understanding of context and intent in a bespoke service.

\subsubsection{Conversational Metrics}
Telemetry \textit{\parencite[pp. 30-60]{Vadapalli2024}} for real-time data collection surrounding user interaction, with privacy-preserving logging mechanisms, once established would be an incredibly utile toolchain for measuring conversational metrics \textit{\parencite[pp. 1-32]{Quarteroni2024}}.
Response accuracy and relevance, plus task completion rates, could be tracked in real-time.


\subsubsection{Usage Analytics}
Common queries and pain points can be identified with usage analytics \textit{\parencite[pp. 50-100]{Beasley2024}}, analysing conversation flows and quality.
Sentiment analysis \textit{\parencite[pp. 50-100]{Liu2024}} can be performed, analysing emotional tone of student interactions.

\subsubsection{Research Collaboration}
    It would be beneficial to foster the academic community, establishing partnerships with universities \textit{\parencite[pp. 50-100]{Dillenbourg2024}} for contribution to research, and ensuring the quality of the service.
    Findings can also be published to contribute to the broader field.

\end{multicols}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Reflection and Recommendations}
Throughout the software development lifecycle, encapsulated here: "privacy by design" from the foundation, with "human-centric AI" as a guiding principle to instill responsibility, and a "mindset for mitigation."
This means optimising for ethical best practice from the foundation up: informed consent built-in, training for all staff, and ultimately assisting the existing school culture to care for students, venerating this ethos above all else.

With ethos-driven targets permeating every aspect of its implementation, Alice must also exemplify educational empowerment for cognitive stewardship, empowering students, educators, and support workers alike. Engineers will have to balance competing priorities effectively (accessibility versus security, privacy versus functionality, etc.).

This can only be achieved through strict data handling, management, and audit procedures. TechSoft must devise training enabling of staff to work effectively alongside AI systems, as opposed to in lieu, or in spite, of them, all the while upholding accountability as a virtue.
Transparency can ensure TechSoft a model for "responsible innovation" in educational AI amongst a sensitive and valued ecology of academia.

In combination with adaptive and continuous evaluation, TechSoft can assure a system that truly serves its mission while protecting student interests, prioritising students foremost and catering to diverse student needs.
TechSoft should maintain an updated Data Protection Impact Assessment, filing and refactoring it according to a robust change policy.

Compliance, accessibility, and effectiveness will naturally converge through thoughtful design choices, iterating to coalesce sensible, successful, and proactive ethical systems and governance structures.

%\vspace{10cm}

%\centering
%\includegraphics[width=0.8\textwidth]{TechSoft.png}
%\caption{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Appendix A: Data Protection Impact Assessment Template}\label{appendix:a}

\begin{multicols}{2}
\subsection*{1. Project Overview}
\begin{itemize}
  \item \textbf{Project Name:} AI Chatbot in Education
    \item \textbf{Data Controller:} South Star Academy
    \item \textbf{System Owner:} TechSoft
      %most recent date
    \item \textbf{Date of Latest Revision:}
\end{itemize}

\subsection*{2. Data Processing Activities}
\begin{enumerate}
    \item \textbf{Nature of Processing}
    \begin{itemize}
        \item Collection methods
        \item Data flows
        \item Retention period and procedure
    \end{itemize}

    \item \textbf{Scope of Processing}
    \begin{itemize}
        \item Types of personal data processed
        \item Volume, aims and scope
        \item Context of processing
    \end{itemize}
\end{enumerate}

\subsection*{3. Necessity and Proportionality}

\begin{enumerate}
  \item \textbf{Lawful Basis for Processing}

\begin{itemize}
    \item Identify relevant Article 6 GDPR condition
    \item Identify Article 9 condition
    \item Justification for chosen basis
\end{itemize}

  \item \textbf{Data Minimisation}
\begin{itemize}
    \item Justification for each data element
    \item Retention periods and rationale
    \item Privacy-preserving measures
\end{itemize}
  \item \textbf{Accuracy Measures}
    \begin{itemize}
        \item Data quality procedures
        \item Update mechanisms
        \item Verification processes
    \end{itemize}
\end{enumerate}

\end{multicols}

\subsection*{4. Risk Assessment}
\begin{longtable}{|p{3cm}|p{4cm}|p{3cm}|p{3cm}|}
    \hline
    \textbf{Risk} & \textbf{Potential Impact} & \textbf{Likelihood (H/M/L)} & \textbf{Mitigation Measures} \\
    \hline
    Data Breach & Unauthorised access to student data & H &  \\
    \hline
    Algorithm Bias & Unfair treatment of certain student groups & M &  \\
    \hline
    Mental Health Impact & Negative psychological effects from AI interactions & M &  \\
    \hline
    Data Accuracy & Incorrect support guidance & M &  \\
    \hline
    System Misuse & Exploitation of AI system & M &  \\
    \hline
\end{longtable}

\vspace{0.5em}
\begin{multicols}{2}
\subsection*{5. Data Subject Rights}
\begin{enumerate}
    \item \textbf{Information Provision}
    \begin{itemize}
        \item Privacy notice content
        \item Rectification and erasure mechanisms
    \end{itemize}
\end{enumerate}

\subsection*{6. Organisational Measures}
\begin{enumerate}
    \item \textbf{Security Standards}
    \begin{itemize}
        \item Network security
        \item Physical security
        \item Staff training
    \end{itemize}

    \item \textbf{Data Protection Measures}
    \begin{itemize}
        \item Data minimisation controls
        \item Purpose limitation safeguards
    \end{itemize}
\end{enumerate}

\subsection*{7. Consultation}
\begin{enumerate}
    \item \textbf{Internal Stakeholders}
    \begin{itemize}
        \item IT Security Team feedback
        \item Legal Team review
        \item Student Support Services input
        \item Senior Management approval
    \end{itemize}

    \item \textbf{External Stakeholders}
    \begin{itemize}
        \item Student representative feedback
        \item Parent consultation
        \item Educational authority guidance
        \item DPO recommendations
    \end{itemize}
\end{enumerate}
\end{multicols}

\subsection*{8. Risk Treatment}
\begin{longtable}{|p{4cm}|p{4cm}|p{4cm}|}
    \hline
    \textbf{Identified Risk} & \textbf{Treatment Measure} & \textbf{Residual Risk Level} \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
    & & \\
    \hline
\end{longtable}


\begin{enumerate}
    \item \textbf{Outcome Decision}
    \begin{itemize}
      \item Proceed with processing: (Y) / (N)
        \item Conditions applied:
    \end{itemize}
\end{enumerate}

\vspace{0.5em}

\subsection*{9. Ongoing Monitoring Plan}
\begin{enumerate}
    \item \textbf{Review Schedule}
    \begin{itemize}
        \item Regular review dates
        \item Trigger events for review
        \item Responsibility assignments
    \end{itemize}

    \item \textbf{Monitoring Measures}
    \begin{itemize}
        \item Performance metrics
        \item Incident reporting
        \item Audit procedures
    \end{itemize}
\end{enumerate}

\vspace{12em}

\subsection*{10. Sign-off}

Information Security Manager:

\vspace{2cm}
\noindent\makebox[8cm]{\hrulefill}
\vspace{0.2cm}
\\\noindent Signature:


\newpage

\section{Appendix B: Regulatory Standards}\label{appendix:b}

\subsection*{DATA PROTECTION LEGISLATION}

\subsubsection*{General Data Protection Regulation (GDPR)}
"
\begin{itemize}
    \item Establishing a lawful basis for processing: Consent or legitimate interests
    \item Implementing data subject rights: Access, rectification, erasure, portability
    \item Appointing a Data Protection Officer (DPO)
\end{itemize}
"

\textit{\parencite{EU2016}}

\subsubsection*{UK Data Protection Act 2018}
"
\begin{itemize}
    \item Adhering to specific provisions for processing personal data in educational contexts
    \item Implementing safeguards for processing special category data (e.g., health information)
\end{itemize}
"

\textit{\parencite{UKGov2018}}:

\subsubsection*{Children's Online Privacy Protection Act (COPPA)}
"
\begin{itemize}
    \item Obtaining parental consent for students under 13
    \item Implementing limited data collection and retention policies
\end{itemize}
"


\textit{\parencite{FTC2024}}

\subsection*{EDUCATION SECTOR REGULATIONS}

\subsubsection*{Education and Skills Act 2008}
"
\begin{itemize}
    \item Fulfilling the duty to promote the well-being of students
    \item Implementing safeguarding responsibilities in digital environments
\end{itemize}
"

\textit{\parencite{UKGov2008}}


\subsubsection*{Keeping Children Safe in Education}
"
\begin{itemize}
    \item Implementing online safety measures for educational technology
    \item Providing staff training on digital safeguarding
\end{itemize}
"

\textit{\parencite{DfE2024a}}

\subsubsection*{Special Educational Needs and Disability (SEND) Code of Practice}
"
\begin{itemize}
    \item Ensuring accessibility requirements for digital learning tools are met
    \item Considering personalised support for students with SEND
\end{itemize}
"

\textit{\parencite{DfE2024b}}


\subsection*{PROFESSIONAL STANDARDS AND GUIDELINES}

\subsubsection*{BCS Code of Conduct}
"
\begin{itemize}
    \item Considering public interest in development decisions
    \item Maintaining professional competence and integrity
    \item Fulfilling duty to relevant authorities
\end{itemize}
"

\textit{\parencite[pp. 1-5]{BCS2024}}


\subsubsection*{ACM Code of Ethics and Professional Conduct}
"
\begin{itemize}
    \item Contributing to society and human well-being
    \item Avoiding harm in system design and implementation
    \item Maintaining honesty and trustworthiness
\end{itemize}
"

\textit{\parencite[pp. 1-4]{ACM2024}}

\subsubsection*{IEEE Ethically Aligned Design}
"
\begin{itemize}
    \item Preserving human rights in AI systems
    \item Ensuring transparency and accountability in AI decision-making
    \item Implementing privacy-by-design principles
\end{itemize}
"

\textit{\parencite[pp. 2-5]{IEEE2019}}


\subsection*{INDUSTRY-SPECIFIC STANDARDS}

\subsubsection*{ISO/IEC 27001:2022}
"
\begin{itemize}
    \item Conducting risk assessment and management
    \item Implementing information security controls
    \item Establishing continuous improvement processes
\end{itemize}
"

\textit{\parencite{ISO2022}}


\subsubsection*{Learning Tools Interoperability (LTI) Standards}
"
\begin{itemize}
    \item Ensuring secure integration with existing learning management systems
    \item Enabling data portability and interoperability
\end{itemize}
"

\textit{\parencite{IMSGlobal2024}}


\subsubsection*{Web Content Accessibility Guidelines (WCAG) 2.2}
"
\begin{itemize}
    \item Ensuring the chatbot interface is perceivable, operable, understandable, and robust
    \item Maintaining compatibility with assistive technologies
\end{itemize}
"

\textit{\parencite{W3C2024}}

\subsection*{ETHICAL AI FRAMEWORKS}

\subsubsection*{UNESCO Recommendation on the Ethics of Artificial Intelligence}
"
\begin{itemize}
    \item Protecting human rights and fundamental freedoms
    \item Promoting diversity and inclusiveness in AI systems
    \item Ensuring transparency and explainability of AI decisions
\end{itemize}
"

\textit{\parencite{UNESCO2022}}

\subsubsection*{OECD AI Principles}
"
\begin{itemize}
    \item Ensuring AI benefits people and the planet
    \item Designing AI systems that respect the rule of law, human rights, democratic values, and diversity
\end{itemize}
"

\textit{\parencite{OECD2024}}

\subsubsection*{EU Ethics Guidelines for Trustworthy AI}
"
\begin{itemize}
    \item Implementing human agency and oversight in AI systems
    \item Ensuring technical robustness and safety
    \item Maintaining privacy and data governance
\end{itemize}
"

\textit{\parencite{EC2024}}

\subsection*{CONTINUOUS COMPLIANCE/ONGOING AUDITING IN PERPETUITY}

\subsubsection*{Regular Compliance Audits}
"
\begin{itemize}
    \item Performing annual data protection audits
    \item Engaging third-party security assessments
\end{itemize}
"

\textit{\parencite{ICO2021}}

\subsubsection*{Continuous Professional Development}
"
\begin{itemize}
    \item Providing regular training on evolving legal and ethical standards
    \item Obtaining certification in AI ethics for key personnel
\end{itemize}
"

\textit{\parencite{IEEE2024}}


\newpage

\printbibliography


\end{document}
